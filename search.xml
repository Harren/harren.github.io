<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[在线广告系统预算控制和流量预估的研究]]></title>
    <url>%2F2017%2F03%2F14%2Ftraffic%2F</url>
    <content type="text"><![CDATA[本文主要是针对国外的计算广告论文 Predicting Traffic of Online Advertising in Real-time Bidding Systems from Perspective of Demand-Side Platforms 进行技术学习的一次分享，同时拓展性的研究了竞价预算和流量预测的方法，具体的参考论文以及实现代码见最后的参考文献地址 随着互联网的发展和用户的增长，广告行业从传统的线下广告模式，逐步转变为线上广告模式，同时，由于大数据分析技术的运用，线上广告模式相比于传统广告也体现了巨大的优越性。广告主之间相互竞争，通过竞价的方式，将自己的广告投放在运营媒体的广告位上。 对需求方平台算法的优化是广大广告主的诉求，是广告网络产品透明化和开放化的催生产物，使得线上广告变得越来越依赖大数据和计算导向的方向发展。预算控制和流量预估的研究是当前的一个热点，流量预测直接影响到广告主获得优质广告流量的能力，进而决定广告预算的性价比并影响广告营销的效果，成为DSP系统(Demand Side Platfrom, 需求方平台)中十分重要的一个环节。 预算控制(Budget Control)预算控制的意义通过实时竞价方式投放在线广告，能够更为准确地将广告的预算花费到那些更有可能产生回报的广告展示机会上，从而使广告收益得到优化，通常情况下，广告商需要为每个广告营销活动设置投放周期内的预算，需求方平台按照一系列优化算法买下尽可能多的符合广告目标群体的广告展示机会，因此，在有限预算的情况下对每次广告展示机会进行出价并给出合理的竞标价格是实时竞价的关键，而针对此的优化算法的主要目标分为以下几点： 满足广告预算的花销计划，广告主希望在广告活动周期内相对平稳的消耗预算，保证在更长时间内有曝光效果，拥有持续性的广告推广效果。 降低数据资讯花费，DSP 通常需要结合自己的第一方数据和来自 DMP 的第三方数据，更好的进行性能评估而做出更理想的决策，减少不必要的数据咨询次数可以降低这方面的经济花销。 同时得到广告的投放和性能目标，对效果类广告来说首要任务是获得性能目标，尽可能的找到更多潜在的客户，对于品牌广告而言则需要达到更多的人群接触，获得更多的投放机会。 为了实现后两个目标，需要依赖广告预算步进算法(Budget Pacing)，步进算法是指对于各种历史行为数据的分析，得出一个符合近期趋势的广告预算的分配计划，这个分配计划是预算的花销额与实践的变化趋势，且去要控制时机的花销进度去接近这个分配计划来最终保证预算的按计划分配。 对于那些没有预算分配计划的广告活动，如图上图所示，可能出现集中恶性的结果： 广告主的广告活动在一天中较早的时间就完全耗尽。而错失之后可能出现的高价值广告流量购买机会。 广告主的出价整体偏低的，难以赢得adx的竞拍，导致预算花费进度不如预期而出现预算剩余，难以达到广告投放目标。 理想的预算控制 为了解决上面的问题，Joaquin等人利用动态规划和变分法证明了理想的预算花费不是线性也不是均匀的，而是正比于广告交易量，也就是广告流量，因此，就产生了一种根据广告流量变化趋势的分配计划，如上图所示。将分配计划正比于广告流量的变化趋势能够使的广告投放到一天内任何一个用户的几率均等，最大程度地保证广告均匀的分配到受众群体上，而不是均匀分布在每个时间段内。 流量预测(Traffic Prediction)论文中提到的流量预测的方法都是基于高维度的特征提取然后建模预估流量，由于可能存在上万种特征，如果不进行降维处理，很难进行运算，因此，从用户特征，上下文，广告属性上万个特征中抽取出具有代表性的基准特征，当产生一次预测时，通过这几种基准特征为标准建立模型来预测流量，这种方法需要极大的训练样本和训练时间，很难在工程上实现。 论文具体算法实现流量问题分析在实际的广告系统中，广告请求数高度依赖于用户的行为，与此同时，用户的行为模式具有一定的规律性，工作日和休息日，白天和晚上所带来的流量请求均有即可循，因此，通过分析用户的行为来预测在线广告的流量走势具有一定的可操作性。 由于不同的时间段流量差异较大，该文将一天按时间分为T个时间段，如果取$T = 24$， 则每天的每个时间段为一个小时，因此，对流量问题的分析模型可以量化为以下公式的求极值的问题。 $${\arg _\Theta }\min \sum\limits_{\forall d,t} {loss(h({X_{d,t}};\Theta ),{Y_{d,t}}),1 \le d \le D,1 \le t \le T}\tag{1} $$ 其中，$D$ 为训练数据的天数， ${Y_{d,t}}$ 为在 d 天的 t 时刻的实际流量，${h({X_{d,t}};\Theta )}$ 为预测模型函数，计算值和实际值的均方差为损失函数，通过训练，寻找最优的模型来使得损失函数最小。 系统框架 上图是整个系统的架构图，利用前D天的历史数据来生成当日的模型，首先提取出前D天的历史数据的特征，然后训练出当天需要用到的数据模型，当需要进行预测的时间点来到的时候，代入当前的时间点的特征，通过流量预测模型来得到此刻时间点的流量。 在整个系统框架中，最重要的为流量预测模型，流量预测模型中首先会更新上一个时间点的真实流量，检测出异常流量并对异常流量进行平滑处理，然后根据历史数据获取到当前的特征，根据获取的特征进行线性回归即可得到真正的预测模型。 特征选取从dsp的角度出发，而不是单纯的利用在线广告的一些特征，提取出一下三个特征 LastNDayReqs: 最近N天的当前Slot点的请求数 LastSlotReqs: 上一次Slot点的请求数(主要针对流量异常的解决方案) SlotNumber: 当前的时间段 其中前两个参数分别代表了长期和短期因素对流量的影响，如果仅仅使用这两个元素的，进行流量预测产生的结果如下所示， 通过图中的对比可以发现，在任意时段对于流量的预测都过高或者过低，当流量发生变化的时候，对于流量的预测总是滞后于实际的流量值，因此，选择 SlotNumber 这一特征来弥补这种差距。 SlotNum 是长度为 T 的一个二进制的一维数组，对于其定义如下 $$SlotNu{m^k}(i) = 1,k = i$$ $$SlotNu{m^k}(i) = 0,k \ne i$$ 其中 ${i \in (1,T)}$，举个例子，当T=24时，则 $$SlotNu{m^1} = [1,0.......0,0]$$ 流量异常处理由于在实际的线上广告系统中，其每天的流量规律往往不是一成不变的，对于流量的预测需要将流量异常的情况考虑在内，产生异常流量的原因主要包括两个部分，一是由于突发性事件造成的流量异常，例如某次事件的爆发，某次网络的迁移等，还有一种就是一种流量趋势的变化，在对流量建模的过程中需要将这种异常情况对于因变量进行一种平滑处理，为了解决流量异常的问题，通过综合考虑前k天的数据来对异常点的流量进行平滑处理。 SmoothedLastSlotReqs通过均衡前k天的t时间点的流量来判断t时间点的流量是否正常，其具体的步骤如下: 获取到上一个时间点t的流量值, 计为 $$originalLastReqs = Reqs(0,t)\tag{2} $$ 其中 $t$ 为当天的时间点，$Reqs$ 为前k天的流量数据，其为二维数组 计算前k天的算术平均值和几何平均值 $$avg = {1 \over k}\sum\limits_{i = 1}^k {Reqs(i,t)}\tag{3} $$ $$st{d^2} = {1 \over k}\sum\limits_i^k {{{(reqs(i,t) - avg)}^2}}\tag{4} $$ 判断实际流量是否是异常流量，如果是正常流量，则不进行平滑，否则进行平滑操作得到最终的 $${{\left\| {originalLastReqs - avg} \right\|} \over {std}} > tol\tag{5}$$ 其中tol为设定的阈值，根据经验值取，如果该计算结果大于预知，则 $$lastSlotReq{s^{k + 1}} = {\rm{ }}\prod\limits_{i = 0}^k {Reqs(k,t)}\tag{6} $$ 反之，则 $$lastSlotReqs = originalLastReqs\tag{7}$$ SmoothedNDayReqs对于 $SmoothedNDayReqs$ 参数的平滑操作类似，由于该特征代表着对于流量的一种长期的效应，如果流量呈现一种上升或者下降的趋势，该特征需要能反映出这种趋势，对于该特征的值的计算如下： $$lastNDaysReq{s^k} = \prod\limits_{i = 1}^k {Reqs(t + 1,i)} \tag{8}$$ PredictTraffic由于对于损失函数的最优化计算是一个不适定的过程，通过引入正则项来求出其最优解，对于公式1增加正则项目修改如下： $${\arg _\Theta }\min \sum\limits_{\forall d,t} {loss(({\omega ^T}{X_{d,t}} + b) - {Y_{d,t}}),1 \le d \le D,1 \le t \le T} \tag{9}$$ 其中， ${X_{d,t}} = [lastNDayreqs,lastSLotreqs,slotNum]$ , ${{\omega ^T}}$ 和$b$为正则项，通过找到使得损失函数最小的$({\omega ^T},b)$来求的最优化模型，得到最优化模型后对于流量预测到步骤如下所示： 获取到最新的最近的流量计为$Reqs(i,j)$,其中 $i$ 为天数，$j$ 为时间片的值。 获取到需要进行预测的时间片的值，计为 $t$。 计算参数 $lastNDayReq{s_t} = SmoothNDayReqs(Reqs,t,T,k)$ 计算参数 $lastSlotReq{s_t} = SmoothLastSlotReqs(Reqs,t,T,k)$ ${X_{t}} = [lastNDayreqs_{t},lastSLotreqs_{t},slotNum_{t}]$ 将参数带入模型计算预测值$h({X_t};\omega ,b)$ 线性回归线性回归的一般问题就是，针对给出的数据，拟合出一个能够较为准确预测出输出结果的线性模型，针对上文定义好的模型进行线性回归: $$f(d,t) = {\omega ^T}X(d,t) + b \tag{10}$$ $$J(\omega ,b) = {1 \over 2}\sum\limits_{d = 1}^D {\sum\limits_{t = 1}^T {{{(f(d,t) - y(d,t))}^2}} } \tag{11}$$ 上式中: $f(d,t)$ 是预测值 $y(d,t)$ 是真实值 $J(\omega ,b)$ 是代价函数 $X(d,t)$是输入值 $\omega ,b$是回归方程需要求解的参数 $J(\omega ,b)$ 表示了预测结果和真实结果的误差，其值越小表明预测结果越接近真实结果，因此，需要找到一组 $J(\omega ,b)$ 使得 $J(\omega ,b)$ 能够最小，根据代价函数，分别求取关于$J(\omega ,b)$的偏导数如下： $${{\partial J(\omega ,b)} \over {\partial \omega }} = \sum\limits_{d = 1}^D {\sum\limits_{t = 1}^T {X(d,t)(f(d,t) - y(d,t))} } \tag{12}$$ $${{\partial J(\omega ,b)} \over {\partial b}} = - \sum\limits_{d = 1}^D {\sum\limits_{t = 1}^T {(f(d,t) - y(d,t))} } \tag{13}$$ 对于 $J(\omega ,b)$ 的最小化的问题，可以将其看作是自变量为$J(\omega ,b)$的函数，这样最小化的问题即可变成函数的极值点为偏导数为0的点，因此: $${{\partial J(\omega ,b)} \over {\partial \omega }} = - \sum\limits_{d = 1}^D {\sum\limits_{t = 1}^T {X(d,t)(f(d,t) - y(d,t))} } = 0 \tag{14}$$ $${{\partial J(\omega ,b)} \over {\partial b}} = - \sum\limits_{d = 1}^D {\sum\limits_{t = 1}^T {(f(d,t) - y(d,t)) = 0} } \tag{15}$$ 求解方程组得到： $$\omega = {{\sum\limits_{d = 1}^D {\sum\limits_{t = 1}^T {(X(d,t) - \bar X(d,t))(y(d,t) - \bar y(d,t))} } } \over {\sum\limits_{d = 1}^D {\sum\limits_{t = 1}^T {{{(X(d,t) - \bar X(d,t))}^2}} } }} \tag{16}$$ $$b = \bar y(d,t) - \omega \bar X(d,t) \tag{17}$$ 上式中 $\bar X(d,t)$ 表示输入参数的均值 $\bar y(d,t)$ 表示实际值的均值 最小二乘法的优势在于计算简单，快速，并且找到的估计参数是全局极小值；缺点是对于异常值极其敏感。 算法结果我们模拟生成近半个月的流量并根据论文的算法进行建模和参数预估，模拟生成半个月的流量数据，并选取其中的最近的7天作为训练样本，即 D = 7,T = 24对生成的数据进行线性回归得到曲线如下，目前只取了前一天的曲线图： 其最近七天的RCO曲线和整体的RCO曲线如下图所示 可以看出，其整体的拟合结果效果只有极少数的点呈现离散。 参考文献 Lai H C, Shih W Y, Huang J L, et al. Predicting traffic of online advertising in real-time bidding systems from perspective of demand-side platforms[C]//Big Data (Big Data), 2016 IEEE International Conference on. IEEE, 2016: 3491-3498. Facebook 广告系统背后的Pacing算法 Github代码地址]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>计算广告</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot整合Quartz定时任务调度]]></title>
    <url>%2F2017%2F02%2F16%2Fspringboot-quartz%2F</url>
    <content type="text"><![CDATA[最近因为项目中涉及到了分布式任务执行的问题，考虑到自己去利用线程池去实现这种定时的任务调度重复造轮子，从整个服务的量级和需求来看，决定在项目中使用Quartz来实现这种分布式的定时任务调度。 _本文中的Springboot版本为1.5.4.RELEASE，Quartz版本为2.2.3_ Quartz能做什么Quartz是一个开源的作业调度框架，它完全由Java写成，并设计用于J2SE和J2EE应用中。它提供了巨大的灵 活性而不牺牲简单性。你能够用它来为执行一个作业而创建简单的或复杂的调度。它有很多特征，如：数据库支持，集群，插件，EJB作业预构 建，JavaMail及其它，支持cron-like表达式等等。 下面进行一个简单的示范例子，设定每分钟在终端打印出一个Hello World. 12345678910111213141516171819202122232425262728293031323334353637public class QuartzTest implements Job &#123; @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; System.out.println("Hello World"); &#125; public static void main(String[] args) &#123; try &#123; // 获取调度器 Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler(); // 创建Job执行类 JobDetail job = JobBuilder.newJob(QuartzTest.class) .storeDurably() .withIdentity("hello world ", "test") .build(); // 创建trigger,每分钟运行一次,无限循环 Trigger trigger = TriggerBuilder.newTrigger() .withIdentity("hello world ", "test") .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInMinutes(1).repeatForever()) .build(); scheduler.scheduleJob(job, trigger); // and start it off scheduler.start(); Thread.sleep(2000); scheduler.shutdown(); &#125; catch (SchedulerException se) &#123; se.printStackTrace(); &#125; catch (InterruptedException ie) &#123; ie.printStackTrace(); &#125; &#125;&#125; Quartz体系结构从上面的例子很好的覆盖了Quartz最重要的3个基本要素: Scheduler(调度器)：代表一个Quartz的独立运行容器， Trigger和JobDetail可以注册到Scheduler中， 两者在Scheduler中拥有各自的组及名称， 组及名称是Scheduler查找定位容器中某一对象的依据， Trigger的组及名称必须唯一， JobDetail的组和名称也必须唯一（但可以和Trigger的组和名称相同，因为它们是不同类型的）。Scheduler定义了多个接口方法， 允许外部通过组及名称访问和控制容器中Trigger和JobDetail。 JobDetail &amp; Job(任务数据): Quartz每次调度Job时， 都重新创建一个Job实例， 所以它不直接接受一个Job的实例，相反它接收一个Job实现类(JobDetail:描述Job的实现类及其它相关的静态信息，如Job名字、描述、关联监听器等信息)，以便运行时通过newInstance()的反射机制实例化Job。 Trigger(触发器)：是一个类，描述触发Job执行的时间触发规则。主要有SimpleTrigger和CronTrigger这两个子类。当且仅当需调度一次或者以固定时间间隔周期执行调度，SimpleTrigger是最适合的选择；而CronTrigger则可以通过Cron表达式定义出各种复杂时间规则的调度方案 Quartz集群架构图Quartz支持单机上的程序调度，其在分布式集群中也有较好的表现，集群的 Springboot集成Quartz]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[互联网DSP广告系统及关键技术分析]]></title>
    <url>%2F2017%2F01%2F16%2Fdsp-infrastructure%2F</url>
    <content type="text"><![CDATA[在互联网广告产业中，DSP是一个系统，也是一种在线广告平台。它服务于广告主，帮助广告主在互联网或者移动互联网上进行广告投放，DSP可以使广告主更简单便捷地遵循统一的竞价和反馈方式，对位于多家广告交易平台的在线广告,以合理的价格实时购买高质量的广告库存。 DSP让广告主可以通过一个统一的接口来管理一个或者多个Ad Exchange账号，甚至DSP可以帮助广告主来管理Ad Exchange的账号，提供全方位的服务。 程序化购买首先先介绍下程序化购买广告系统的相关概念: Ad Network(广告网络)。聚合多种展示类广告媒体资源，旨在提升广告主媒体购买的效率。 ADX(Ad Exchange, 广告交易平台)。集合不同网络以及网站整合出的技术平台，旨在促成广告主以及网站主以竞价方式进行的媒体购买。 DSP(Demand Side Platform，广告需求方平台)。DSP为广告主提供跨媒体、跨平台的广告投放平台，通过数据整合分析实现基于用户的精准投放，并不断优化投放效果。 SSP(Supply Side Platform，供应方平台)。SSP主要是针对广告主的服务提供商，协助网站拥有者将其广告位资源加入广告交易平台，并通过数据化方式管理其广告资源，旨在提升网站拥有者从广告交易平台中获取的收入。 RTB(Real Time Bidding，实时竞价)。实时竞价是DSP、广告交易平台在网络广告投放中才用的主要售卖方式，会在极短的时间内通过对目标受众竞价对方式获得该次广告的展现。 DMP(Data Management Platform，数据管理平台)。将分散的多方数据纳入统一的技术平台，并对数据进行标准化和细分、便签化管理，为DSP等提供数据支持，获得更好的投放效果。 DSP的特点下图是DSP平台的广告投放流程，投放过程中涉及到广告受众，媒体网站，adx和dsp，分别标注了广告投放各阶段伴随发生的事件。从1~7步之间只允许100ms之内的延时，否则广告受众就会觉得网页加载速度太慢而选择离开。 一般市面上比较优秀的dsp存在以下几个特点 全方面的投放优化手段基于人群浏览轨迹综合分析，把握住用户的短期购买倾向、长期偏好等，在此基础上可动态调整定向人群等，能够实现多种全方位的定向，目前常见的dsp广告样式如下 媒体资源丰富DSP可以投放到各家媒体的各个广告位，涵盖到目前网络上的各个站点，包括各种新闻传媒和社交工具端均可以看到dsp广告的身影，如此多的广告资源接入对于广告主而言具有很好的广告投放资源。 精准投放先进的用户定向技术(Audience Targeting)技术。服务于广告主或者广告主代理的DSP，则需要对Ad Exchange每一次传过来的曝光机会，根据关于这次曝光的相关数据来决定竞价策略。这些数据包括本次曝光所在网站、页面的信息，以及更为关键本次曝光的受众人群属性，人群定向的分析直接决定DSP的竞价策略。DSP在整个过程中，通过运用自己人群定向技术来分析，所得出的分析结果将直接影响广告主的广告投放效果 DSP系统架构 DSP整个流程中的角色包括广告主网站，媒体网站，广告网络和DSP，以及DSP内部的相关模块，如：RTB引擎，业务平台，日志收集系统，DMP，CM和反作弊系统。 投放前DSP会要求在广告主网站布码，同时在DSP的业务平台中录入广告投放的需求，如投放金额，投放排期，投放定向（如地域，兴趣，年龄等），最高限价。 当访客（即潜在的消费者）从左上角访问广告主网站开始，访客在广告主网站上的行为会被收集，同时DSP会与ADX和SSP进行Cookie Mapping，形成日志进行处理，形成回头客相关的行为数据标签。 当访客完成对广告主网站的访问，去其他媒体网站进行访问时，相应的媒体广告位根据事先嵌入的广告代码向广告网络发起广告请求，广告网络会将广告请求封装成http头 pb体的格式向多个DSP发起竞价请求。 当DSP接到竞价请求时会根据与广告网络约定的pb格式进行解包，拆解出相关的字段进行匹配，根据之前相关媒体积累的点击率结合点击率预测模型对出价进行预测，找出平台内在此次竞价请求能让平台利益最大化的广告主的创意进行投放，返回给广告网络出价与广告代码 广告网络会在特定时间内（通常是50~100毫秒）根据多个DSP的出价高低，以第二名价格多一分的价格让出价最高的dsp胜出，并将广告代码中的展现宏和点击宏进行替换（替换过程中会根据事先与dsp约定好的公钥对价格进行加密，以防止第三方篡改和窃听） 广告网络将广告代码返回给媒体，媒体会将广告代码放置在js对应的位置进行展现，展现和点击的过程中会先后触发广告网络和胜出DSP的展现代码，广告网络和DSP分别接收到展现请求会对相应的展现进行计费操作（月底会相互进行对账） DSP内部会根据收集到的展现和点击进行计费操作，形成相应的报表；而浏览、展现、点击的记录会分别进行收集形成日志，经过ETL由DMP进行抽取和分析，形成媒体数据，用户标签，CookieMatch数据以及回头客用户标签数据，这些数据会在投放过程中作为RTB竞价的参考依据。 整个投放过程中其实还有一些其他的模块出现如CookieMapping、反作弊，动态创意、网站分析系统。只不过这些系统不是在主干流程上，后续单独进行描述和分析。 为了保证投放，DSP系统实现了多机房部署的结构，南北方机房分别在杭州和北京部署RTB引擎、点击率预测与相关的展现点击收集节点。投放活动相关数据通过Redis进行缓存，多机房进行准实时同步，媒体展现点击数据通过kafka队列进行推送，通过Consumer进行消费统计，最后通过媒体数据分发集群分发到多个机房进行使用。 RTB投放引擎架构RTB引擎是DSP系统的核心，是实现高并发实时反馈的关键，RTB对外以HTTP服务形式暴露接口，当媒体上的js被触发，adx/ssp收到js请求后会将请求封装成http头+pb体(protocol buffer,谷歌定义的序列化数据交换格式)的方式作为客户端连接RTB，RTB对http消息按照事先约定解包在内部依靠相关数据进行计算，最终返回pb或json格式的出价和广告代码给广告交易平台。RTB 需要支持高并发（每天百亿级别请求）和低延时（50ms之内需要反馈）。 当时我们的RTB采用Linux C++开发，通过Adapter适配器层解耦适应不同的SSP/adx，算法池内部拆分成五层，五层之间相互正交，算法模块允许热插拔，编译完成的动态链接库可根据配置文件的变化实时进行加载和卸载，允许多算法链并行拆分流量进行A/B测试，流量处理过程中会对流经不同算法链的流量打上不同的算法标签，并在后续展现，点击过程中持续带上此标签用于后续效果的跟踪和分析。** DMP数据处理架构todo 用户画像todo 广告行业的反作弊todo 参考资料1.《高可用架构》2.7章]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>高可用架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发-Executors框架和线程池]]></title>
    <url>%2F2017%2F01%2F12%2Fexecutor-infrastructure%2F</url>
    <content type="text"><![CDATA[为了避免系统频繁的创建和销毁线程，通常会让创建的线程进行复用。一般我们进行数据库开发的时候，为了避免每次数据库查询都重新建立和销毁数据库连接，我们可以利用数据库连接池维护一些数据连接，让其长期保持在一个激活的状态，当需要使用数据库的时候，并不是创建一个连接，而是从连接池中获取一个可用的连接。 线程池也是和数据库连接池类似的概念。线程池中总有几个活跃的线程，当你需要使用线程时，可以直接从池子里随便拿出一个空闲的线程，完成任务后将线程退回到池子。 Executors框架Eexecutor作为灵活且强大的异步执行框架，其支持多种不同类型的任务执行策略，提供了一种标准的方法将任务的提交过程和执行过程解耦开发，基于生产者-消费者模式，其提交任务的线程相当于生产者，执行任务的线程相当于消费者，并用Runnable来表示任务，Executor的实现还提供了对生命周期的支持，以及统计信息收集，应用程序管理机制和性能监视等机制。JDK提供了一整套的Executor框架来进行线程控制，其主要成员如下：其中： Executor 执行器接口，该接口定义执行Runnable任务的方式。 ExecutorService 该接口定义提供对Executor的服务。 ScheduledExecutorService 定时调度接口。 AbstractExecutorService 执行框架抽象类。 ThreadPoolExecutor JDK中线程池的具体实现。 Executors 线程池工厂类。 ExecutorService的生命周期包括三种状态：运行、关闭、终止。创建后便进入运行状态，当调用了shutdown()方法时，便进入关闭状态，此时意味着ExecutorService不再接受新的任务，但它还在执行已经提交了的任务，当素有已经提交了的任务执行完后，便到达终止状态。如果不调用shutdown()方法，ExecutorService会一直处在运行状态，不断接收新的任务，执行新的任务，服务器端一般不需要关闭它，保持一直运行即可。 Executor框架提供了各种类型的线程池，主要有以下几个工厂方法： 12345678910/***创建固定大小的线程池***/public static ExecutorServcie newFixedThreadPool(int nThread);/***单线程的线程池***/public static ExecutorServcie newSingleThreadExecutor();/***可缓存的线程池***/public static ExecutorServcie newCachedThreadPool();/***定时任务调度的线程池***/public static ExecutorServcie newSingleThreadScheduledExecutor();/***单线程的定时任务调度线程池***/public static ExecutorServcie newScheduledThreadPool(int corePoolSize); newFixedThreadPool返回一个包含指定数目线程的线程池，如果任务数量多于线程数目，那么没有没有执行的任务必须等待，直到有任务完成为止。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程，简单的展示一下该类线程池的使用 12345678910111213141516public class ThreadPoolDemo &#123; public static void main(String[] args) &#123; int poolSize = 5; ExecutorService es = Executors.newFixedThreadPool(poolSize); for(int i = 0;i &lt; 10;i++) &#123; es.submit(new Runnable() &#123; @Override public void run() &#123; System.out.println("thread begin"); &#125; &#125;); &#125; &#125;&#125; newSingleThreadExecutor该方法返回一个只有一个线程的线程池，若多于一个任务被执行到该线程池，任务会被保存在一个任务队列，等到线程空闲的时候按照先入先出的顺序执行，适用于需要顺序执行的场景。 newCachedThreadPool该方法返回一个可根据实际情况调整线程数量的线程池，适用于线程池的线程数量不确定，但是又需要即时执行的场景，若当前有空闲线程可复用，则会优先使用可复用的线程，否则会创建新的线程处理任务(PS:如果使用不当会有OOM的风险)。 newSingleThreadScheduledExecutor该方法返回一个ScheduledExecutorService对象，线程池大小为1, ScheduledExecutorService对象拓展了在给定时间定时执行某任务的功能，例如在某个固定的延时之后执行，或者周期性执行某个任务，其任务调度的方式有三种： schedule() 在给定的时间，对任务执行一次调度 scheduleAtFixedRate() 按照一定的频率进行调度，类似于linux的定时任务，以执行时间为起点，每个一定的周期执行，它不会关注上一次执行的状态，适用于能准确估计任务执行时间的场景。 scheduleWithFixedDelay() 在上一次任务结束后，在经过delay时间后进行调度，它需要知道上一次任务执行的状态，适用于调度任务执行时间不确定的场景。 123456789101112public static void main(String[] args) &#123; int coreSize = 10; // the number of threads to keep in the pool ScheduledExecutorService ses = Executors.newSingleThreadScheduledExecutor(); //ses.scheduleWithFixedDelay( ses.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; System.out.println("just test"); &#125; &#125;, 0, 2, TimeUnit.SECONDS); &#125; newScheduledThreadPool该方法返回一个ScheduledExecutorService对象，和newSingleThreadScheduledExecutor的区别在于可以指定线程数量 线程池的内部实现对于以上介绍的核心的几个线程池，尽管在功能上具有不同的特点，但是其内部实现均使用了ThreadPoolExecutor实现，下面给出几个线程池的实现方式： 123456789101112131415161718public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125;public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 以上的实现代码可以看到，核心的线程实现都是ThreadPoolExecutor的封装，其构造函数如下 12345678public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler)&#125; 各个参数的含义如下： corePoolSize: 指定线程池中的线程数量。 maximumPoolSize: 指定线程池中的最大线程数量。 keepAliveTime: 当线程池线程数量超过corePoolSize时，多余的空闲线程的存活时间，即超过corePoolSize的空闲线程，在多长时间内，会被销毁。 unit: keepAliveTime的单位。 workQueue: 任务队列，被提交但尚未执行的任务。 threadFactory: 线程工厂，用于创建线程，一般默认即可。 handler: 拒绝策略。当任务来不及处理时候如何拒绝任务 任务队列workQueue用于存放Runnable对象，它是一个BlockingQueue接口的对象，可以使用以下几种几种BlockingQueue。 直接提交的队列：通过SynchronousQueue队列实现，该队列没有容量，因此每次提交的任务都不会真实的保存，如果没有空闲的线程，则会尝试创建新的线程，如果达到进程的最大值，则会执行拒绝策略，如果使用这种队列，往往需要设置较大的maximumPoolSize。 有界的任务队列：通过ArrayBlockingQueue实现。由于是数组，所以其构造需要指定容量参数。当有新的任务需要执行时，如果线程池的线程数小于corePoolSize，则会创建新的线程，反之，则将该任务加入队列，如果队列装满时，则会将线程数提升到maximumPoolSize后，就不会再增加，后续仍有新任务执行则直接执行拒绝策略。 无界的任务队列：通过LinkedBlockingQueue实现。由于是无解的任务队列，当系统的线程数小于corePoolSize数时，线程池会生成新的线程执行任务，反之，则任务直接加入队列进行等待，一但任务处理速度跟不上线程的创建速度，无界队列会无限增长，直到耗尽系统内存。 优先任务队列：通过PriorityBlockingQueue实现，它是一个特殊的无界队列，它可以根据自身任务的优先级瞬息先后执行而不用考虑先进先出。 结合目前的介绍，可以分析出newFixedThreadPool()由于固定了线程池，其使用了LinkedBlockingQueue作为任务队列。 newSingleThreadExecutor()返回的单进程线程池，是线程池数量为1的newFixedThreadPool()。 newCachedThreadPool()返回了corePoolSize为0，maximumPoolSize为无穷大的线程池，其将任务加入SynchronousQueue队列，而SynchronousQueue队列是直接提交的队列，它会迫使线程池增加新的线程执行任务。 拒绝策略前面介绍到的，当任务数量超过系统实际承载压力时，这个时候对于后续进来的任务就需要进行拒绝，避免系统压力太大而直接崩掉，jdk内置的拒绝策略包含以下四种： AbortPolicy策略: 直接抛出一场，阻止系统正常工作。 CallerRunsPolicy策略: 只要线程池未关闭，会直接在调用者线程中运行当前被丢弃的任务，虽然并不会丢弃任务，但是，任务提交线程的性能会急剧下降。 DiscardOledestPolicy策略: 丢弃最老的一个请求，也就是被执行的一个任务，并尝试再次提交当前任务。 DiscardPolicy策略: 丢弃无法处理的任务，不予任何处理。 如果以上的策略无法满足需求，完全可以自定义拒绝策略，下面代码简单的演示自定义线程池和拒绝策略的使用： 123456789101112131415161718public static void main(String[] args) &#123; ExecutorService es = new ThreadPoolExecutor(0, 100, 0L, TimeUnit.MILLISECONDS, new SynchronousQueue&lt;&gt;(), new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; // 自定义线程生产 return null; &#125; &#125;, new RejectedExecutionHandler() &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; // 自定义拒绝策略 &#125; &#125;); &#125; 参考资料 Java高并发程序设计]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xmpp协议解析与使用]]></title>
    <url>%2F2017%2F01%2F07%2Fxmpp%2F</url>
    <content type="text"><![CDATA[XMPP 是基于 XML 的协议，用于即时消息( IM )以及在线现场探测。最初, XMPP 作为一个框架开发, 目标是支持企业环境内的即时消息传递和联机状态应用程序 。当时的即时消息传递网络是私有的,不适合企业使用 XMPP 前身是 Jabber ( 1998 年) ,是一个开源组织定义的网络即时通信协议XMPP 是一个分散型通信网络 ,这意味着,只要网络基础设施允许,任何XMPP 用户都可以向其他任何 XMPP 用户传递消息。多个 XMPP 服务器也可以通过一个专门的“服务器 - 服务器 “协议相互通信,提供了创建分散型社交网络和协作框架的可能性。注意，分属于不同server的client之间要通信的话，中间不能再经过其他server，这2个server必须直接通信。对于XMPP来说，server不能象email server那样，中间可以经过若干个server才能把邮件发送到目的地 XMPP协议优缺点 优点 开放 标准( XMPP 的技术规格已被定义在 RFC 3920 及 RFC 3921 ) 证实可用 分散 安全 可扩展 缺点 数据负载过重 没有二进制传输 为什么选择XMPP 1.通信原语 Message Stanza、Presence Stanza和IQ Stanza(IQ节) 2.XMPP协议引入了XML Stream(XML流)和XML Stanza(XML节) 伸缩架构 负载均衡：是通过负载策略分发客户端请求，后端的连接管理器退出服务后，请求不在分发给本台连接管理器。 连接管理器：是保存客户端连接，实现系统用户并发上的可伸缩，连接服务器不包含业务逻辑代码它的功能只是负载保持客户连接和转发客户请求。 业务服务器：业务逻辑都实现在业务服务器包括用户验证模块、用户会话模块、在线状态模块、路由模块、文本消息模块等。 组件服务器：是用于扩展非即时通讯本身核心功能的业务，是通过业务服务器包路由过来的客户端请求，并通过组件服务器应答客户端。 代理服务器：是负责适配不同即时通讯协议实现不同即时通讯的互联。 为什么使用openfireA、Openfire为Java开源项目 B、采用开放的XMPP协议 C、有多种针对不通系统的版本 D、使用Socket通讯 E、 单台服务器可支持上万并发用户,搭建分布式云服务器可轻松提供大量并发用户。 F、 Socket长连接 G、服务器稳定小 H、提供接口，可自己开发插件 JabberD2组件 路由(router):路由器是jabberd的核心组件，它从其他组件接受信息，并把各个组件间传递xml数据包 服务器－服务器(s2s):S2S控制和其他服务器的通信，并实现服务器回呼和远程jabber服务器的验证 分解器(resolver):分解器是为支持S2S工作的.他为S2S回呼中验证部分提供分解主机名服务 会话管理(Session Manager):SM(会话管理)实现了即时消息的大部分 - 消息传送 - 状态管理(Presence) - 帐户管理(Rosters) - 订阅(Subscriptions) 客户端－服务器端(c2s): C2S组件控制与客户端的通信 - 和jabbar客户端连接 - 传递包给SM - 验证客户端 - 注册用户 - 同SM引发活动 数据控制jabberd 使用数据控制(data handing)的概念以便适应各类数据处理包。数据控制(data handling)的核心是收集器(Collection)对象概念。每个收集器(Collection)都有类型(Type)和拥有者(Owner)两个属性.类型(Type)指明什么类型的数据正在被处理,如,队列(queue),vcard,名册条目(roster-item). 拥有者(Owner)表明谁拥有这个收集器(collection).对于和用户相关的数据，拥有者(Owner)是jabber ID(JID). JIDjid为客户端的唯一性标识id，{$user}@{$host}组成一个唯一性jid／{$work}，根据work用于将数据发送到与他的工作相关的工具 参考文献 XMPP权威指南 XMPP-RFC3920]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pinpoint简单介绍以及应用实例]]></title>
    <url>%2F2016%2F12%2F28%2Fpinpoint%2F</url>
    <content type="text"><![CDATA[Pinpoint是一个开源的APM(Application Performance Management/应用性能管理)工具，用于基于Java的大规模分布式系统，思路基于google Dapper，用于基于java的大规模分布式系统，通过跟踪分布式应用之间的调用来提供解决方案，以帮助分析系统的总体结构和内部模块之间如何相互联系，其开发的初衷主要基于以下思考元素。 系统架构Point是基于Google Dapper，主要有三个组件： pinpoint-collector，日志收集器模块，主要手收集从agent端传来的数据信息并存储 pinpoint-web，控制台视图模块，主要将collector的数据可视化的展示给用户 pinpoint-agent，日志代理客户端模块，用于在客户段进行埋点来获取到监控信息 同时使用Hbase作为存储，point主要特点如下图，包括以下几点 分布式事务跟踪，跟踪跨越分布式应用的消息 自动检测应用拓扑，帮助你搞清楚应用的架构 水平拓展以便支持大规模服务器集群 提供代码级别的可见性以便轻松定位失败点和瓶颈 使用字节码增强技术，添加新功能无需修改代码(AOP技术) 在比较复杂的系统中利用pinpoint可以有效的看到系统的瓶颈，其常用功能如下所示： 主要技术Pinpoint的主要技术设计到分布式事务跟踪，主要分为两个主要技术：事务追踪技术以及字节码增强技术来实现无侵入式的性能监控 数据结构Pinpoint跟踪单个事务的分布式请求，分布式追踪系统的核心是在分布式系统中识别在Node1中处理的消息和在Node2中出的消息之间的关系。HTTP请求中的HTTP header中为消息添加一个标签信息并使用这个标签跟踪消息，即TraceID，Pinpoint中，核心数据结构由Span，Trace和TraceID组成: Span:跟踪的基本单元，包含一个TraceId Trace:多个Span集合，由关联的RPC（Spans）组成，同一个trace共享一个相同的TransactionID,Trace通过SpanId和ParentSpanId整理继承树结构。 TraceID:由 TransactionId, SpanId(64位长度的整型), 和 ParentSpanId(64位长度的整型) 组成的key的集合. TransactionId 指明消息ID，而SpanId 和 ParentSpanId 表示RPC的父-子关系 TransactionId：AgentIDs(建议使用hostname，服务器IP),JVM启动时间以及序列号组成 生成唯一性ID的方法，通过中央key服务器来生成key。如果实现这个模式，可能导致性能问题和网络错误，因此，大量生成key被考虑作为备选。 Trace行为下图5描述在4个节点之间进行3次rpc调用： 上图中，TransactionID(TxId) 体现了三次不同的rpc作为单个事务被相互关联，由于 TransactionID 本身不能精确描述rpc之间的关系，为了识别 rpc 之间的关系，需要 SpanId 和 ParentSpanId， 假设一个节点是 Tomcat， 可以将 SpanId 想象为出力http请求的线程，ParentSpanId 代表发起这个rpc调用的 SpanId。 SpanId 和 ParentSpanId 是64位长度的整型，由于这个数字是任意生成的，但是考虑到值的范围从 -2^64 ~ 2^64， 不太可能发生冲突，如果发生冲突，系统会让开发者知道发生了什么，而不是去解决冲突。 字节码增强实现分布式事务跟踪的实现方法之一是开发人员自己修改代码，在发生rpc调用的地方开发人员自己添加标签信息，这就需要修改到项目代码，对代码有一定的侵入性，为了解决这个问题，pinpoint中使用了字节码增强技术，由 pinpoint-agent 干预发起rpc的代码来实现自动处理标签信息，如下图 在程序编译阶段通过反射方式注入代码来实现无侵入的埋点，这种代码跟踪方式于手工跟踪对比如下图8所示 只需要在项目启动的过程中加入 agent 即可实现性能监控 123javaagent:$AGENR_PATH/pinpoint-bootstrap.jar-Dpinpoint.agentId=&lt;Agent’s UniqueId&gt;-Dpinpoint.applicationName=&lt;the name of service&gt; 应用分析阐述point为每个方法做了什么： 请求到达tomcatA时，Pinpoint agent产生TraceID 从springMVC控制器记录数据 插入HttpClient.execute()方法的调用并在HttpGet中配置TraceId 传输打好tag的请求到tomcatB 从springmvc控制器中记录数据并完成请求 从tomcatB回来的请求完成时，pp-agent发送跟踪数据到pp-collector存储在hbase 在对tomcatB的http调用结束后，tomcatA的请求也完成，pp-agent发送跟踪数据到pp-collector存储在HBase中 UI从Hbase中读取数据并通过排序树来创建调用栈 整体的应用分析如下图所示 参考文献 Pinpoint源码 Techinal Overview Of Pinpoint (包含中文手册)]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>性能监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sonar代码质量分析使用]]></title>
    <url>%2F2016%2F12%2F17%2Fsonar-mannual%2F</url>
    <content type="text"><![CDATA[Sonar概述Sonar是一个用于代码质量管理的开放平台。通过插件机制，Sonar 可以集成不同的测试工具，代码分析工具，以及持续集成工具。 与持续集成工具（例如 Hudson/Jenkins 等）不同，Sonar 并不是简单地把不同的代码检查工具结果（例如 FindBugs，PMD 等）直接显示在 Web 页面上，而是通过不同的插件对这些结果进行再加工处理，通过量化的方式度量代码质量的变化，从而可以方便地对不同规模和种类的工程进行代码质量管理。 在对其他工具的支持方面，Sonar 不仅提供了对 IDE 的支持，可以在 Eclipse 和 IntelliJ IDEA 这些工具里联机查看结果；同时 Sonar 还对大量的持续集成工具提供了接口支持，可以很方便地在持续集成中使用 Sonar。此外，Sonar的插件还可以对 Java 以外的其他编程语言提供支持，对国际化以及报告文档化也有良好的支持。 Sonar安装本文主要介绍 Sonar 的使用方法，直接到Sonar官网下载最近的发型包即可，本文使用的为最新的版本为6.5(推荐使用最新版)，其源代码可以参考github地址。 下载zip包后，直接解压，然后根据应用服务器环境启动 bin 目录下的脚本即可 12bin/linux-x86-64/sonar.sh -h // 显示所有命令bin/linux-x86-64/sonar.sh start // 启动，默认为9000端口 然后在浏览器中访问 http://localhost:9000 即可, 初始化用户名和密码为: admin/admin Sonar数据库配置Sonar 默认使用的是 Derby 数据库，但这个数据库一般用于评估版本或者测试用途。商用及对数据库要求较高时，建议使用其他数据库。Sonar 可以支持大多数主流关系型数据库（例如 Microsoft SQL Server, MySQL, Oracle, PostgreSQL 等，本文以 MySQL 为例说明如何更改 Sonar 的数据库设置: 12mysql&gt; CREATE USER sonar IDENTIFIED BY &apos;sonar&apos;;mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;sonar&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;sonar&apos; WITH GRANT OPTION; 配置好数据库权限后，修改 sonar.properties 文件配置如下(数据库用户名密码为：sonar/sonar)配置后重新启动sonar即可，此次因为需要创建数据库，重启较慢，重启成功后会在数据库中生成sonar相关的表。 使用Sonar进行代码质量管理由于本人主要使用 Java 作为开发工具，主要介绍对 Java 代码代码质量管理，sonar默认是不需要登录权限认证就可以上传代码监测报告的，在生产环境中需要打开用户权限，在[配置]-&gt;[通用配置]-&gt;[权限]中打开即可，如下图所示 Maven集成SonarMaven 插件会自动把所需数据（如单元测试结果、静态检测结果等）上传到 Sonar 服务器上，需要说明的是，关于 Sonar 的配置并不在每个工程的 pom.xml 文件里，而是在 Maven 的配置文件 settings.xml 文件里，涉及到以下 maven 配置项目: 配置项 作用 默认值 sonar.host.url sonar服务器地址文件 http://127.0.0.1:9000 sonar.login sonar用户名 用户或者token(如果利用token则不用密码，推荐这种方式登陆) sonar.password sonar密码 admin sonar生成登陆token为了强化安全，避免直接暴露出分析用户的密码，使用用户令牌来代替用户登陆,如下图 Maven配置文件修改具体配置如下: 12345678910&lt;profile&gt; &lt;id&gt;sonar&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;sonar.host.url&gt;http://localhost:9000&lt;/sonar.host.url&gt; &lt;sonar.login&gt;93a87b9d138cd836b65c2c52fc5578fc71270707&lt;/sonar.login&gt; &lt;/properties&gt; &lt;/profile&gt; 编译命令如下 12mvn clean installmvn sonar:sonar 将 Soanr 所需要的数据上传到 Sonar 服务器上之后，Sonar 安装的插件会对这些数据进行分析和处理，并以各种方式显示给用户，从而使用户方便地对代码质量的监测和管理，之后可以在sonar服务器得到上此次提交代码分析的结果信息，包括代码覆盖率等信息。 Sonar配置Gitlab可持续集成自动化脚本集成如果对项目有持续即成的需要，同时项目是利用gitlab进行托管，给项目配置好runner，则需要在项目目录下建.gitlab-ci.yml文件来自定义命令，具体参照gitlab-ci使用简介 ，这样每次提交的时候都会自动运行脚本，并将生成的报告直接上传到服务器，下面提供一个参考脚本如下 123456789101112131415161718# 定义 stagesstages: - review - analyze# 定义 reviewjob1: stage: review script: - /usr/local/sbin/code_analyze --preview #这条命令主要是将代码分析的信息输出到gitlab的Discussions，只会在分支上运行 except: - master# 定义 analyzejob2: stage: analyze script: - /usr/local/sbin/code_analyze #这条命令主要是将代码分析的信息同步到sonar服务器，只针对master only: - master code_analyze为脚本文件，主要是对git项目内容进行打包并将相应的代码分析报告上传到sonar服务器，其内容如下 1234567891011121314151617181920212223#!/bin/bashset -eecho "test"if [ "$1" = "--preview" ];then echo $&#123;CI_BUILD_REF&#125; echo $&#123;CI_BUILD_REF_NAME&#125; echo $&#123;CI_PROJECT_DIR&#125; echo $&#123;CI_PROJECT_ID&#125; sonar_prop="-Dsonar.issuesReport.console.enable=true -Dsonar.analysis.mode=preview -Dsonar.preview.excludePlugins=issueassign,scmstats -Dsonar.gitlab.commit_sha=$&#123;CI_BUILD_REF&#125; -Dsonar.gitlab.ref=$&#123;CI_BUILD_REF_NAME&#125; -Dsonar.gitlab.project_id=$&#123;CI_PROJECT_ID&#125;" if [ -f "gradlew" ]; then ./gradlew clean check sonarqube $sonar_prop else mvn --batch-mode clean verify sonar:sonar $sonar_prop fielse sonar_prop="-Dsonar.preview.excludePlugins=gitlab" if [ -f "gradlew" ]; then ./gradlew clean check sonarqube $sonar_prop else #mvn clean org.codehaus.mojo:cobertura-maven-plugin:2.7:cobertura -Dcobertura.report.format=xml -Dcobertura.aggregate=true mvn --batch-mode verify sonar:sonar $sonar_prop fifi Sonar写入Gitlab Discussion如果希望直接在 gitlab 的每次 Merge_requesrs 中在 gitlab 的 Discussion 中显示出此次代码分析的结果，效果如下 首先，需要gitlab给sonar授权，在 gitlab 中 ［User Settings］中生成 Access Tokens 然后在 sonar 的配置页写入token, 如下，由于申请的 token 的作用域为 api, sonar里面配置 scope 为 api 配置完后，在gitlab上之执行Merge Request时候会出发自动构建，同时生成相应的isscus。 参考资料 Sonar官方文档 Sonar插件下载地址]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>代码质量分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab-CI持续集成]]></title>
    <url>%2F2016%2F11%2F27%2Fgitlab-ci%2F</url>
    <content type="text"><![CDATA[持续集成 (Continuous Integration) 是一种软件开发实践，即团队开发成员经常集成他们的工作，通过每个成员每天至少集成一次，也就意味着每天可能会发生多次集成。每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，从而尽早地发现集成错误，同样在《Code Complete》里提到了，对于持续集成（在书中，Steve McConnell使用Incremental Integration的术语）有以下几点好处： 易于定位错误，当集成失败后很容易及时的找到问题所在 模拟生产环境的自动测试 与其它工具结合的持续代码改进，比如Sonar,findbug等 方便进行Code Review Gitlab-Runner在Gitlab-CI中有一个叫 Runner 的概念, 按照官方定义, Runner一共有三种类型 本地Runner (优点:部署方便, 缺点:使用的是开发机器的资源， Runner服务无法持久化) 普通的服务器上的Runner (本文主要用的这种Runner) 基于Docker的Runner (没有较好的docker环境，如果存在docker集群的话推荐使用) GitLab-Runner类似于一个用来执行软件集成脚本的东西，它负责将Git仓库的代码 Clone 到 Runner所在到服务器上，然后运行软件集成脚本，同时将脚本输出的内容写回Git,如下图所示 Runner 可以分布在不同的主机上，同一个主机上可以根据不同的项目注册多个 Runner。 Gitlab-Runner安装直接参考官网教程安装 12345678910# For MacOS brew install gitlab-ci-multi-runner# For Debian/Ubuntu curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-ci-multi-runner/script.deb.sh | sudo bashsudo apt-get install gitlab-ci-multi-runner# For RHEL/CentOS curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-ci-multi-runner/script.rpm.sh | sudo bashsudo yum install gitlab-ci-multi-runner 使用gitlab-ci-multi-runner注册Runner安装好gitlab-ci-multi-runner这个软件之后，我们就可以用它向GitLab-CI注册Runner了，Gitlab-Runner可以分为两种类型: Shared Runner: 共享型，这个需要gitlab管理员创建。 Specific Runner: 指定型，拥有项目工程访问权限的人都可以创建(本文主要创建该类型Runner) 向GitLab-CI注册一个Runner需要两样东西：GitLab-CI的url和注册token。其中，token是为了确定你这个Runner是所有工程都能够使用的Shared Runner还是具体某一个工程才能使用的Specific Runner。 首先，在gitlab项目配置上选中 Runners, 然后会出现相应的ci绑定Runner的配置选项根据项目设置中的 url 和 token , 在服务器上注册Runner， 12345678910111213141516#然后启动Runner去和CI进行绑定$ gitlab-ci-multi-runner registerRunning in System-modePlease enter the gitlab-ci coordinator Url:#--&gt;然后让你输入上图的CI URLPlease enter the gitlab-ci token for thus runner:#--&gt;然后让你输入上图的TokenPlease enter the gitlab-ci description for this runner:#--&gt;然后随便给Runner命名Please enter the gitlab-ci tags for thus runner(comma separated):Please enter the executor:#--&gt;然后类型的话， 请务必选 Shell#--&gt;完毕$ gitlab-ci-multi-runner list // 查看是否注册成功$ gitlab-ci-multi-runner start // 把Runner当成Service启动 如果注册的Runner和Gitlab连接上则会出现绿色Runner证明可用 Runner使用在git项目根目录下创建文件 .gitlab-ci.yml 脚本 12build: script: "pwd &amp; mvn test" 在 Pipelines 中运行，即会自动运行脚本进行构建并输出构建结果，之后每次提交代码都会进行集成测试，保证每次的提交都是正确的 参考资料 Gitlab-Runner GitLab CI持续集成配置方案]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFmpeg命令行转压视频]]></title>
    <url>%2F2016%2F10%2F14%2Fffmpeg-guide%2F</url>
    <content type="text"><![CDATA[FFmpeg是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。采用LGPL或GPL许可证。它提供了录制、转换以及流化音视频的完整解决方案。它包含了非常先进的音频/视频编解码库libavcodec，为了保证高可移植性和编解码质量，libavcodec里很多code都是从头开发的。 安装直接到官网http://ffmpeg.org/download.html根据系统下载对应的版本即可，建议直接下载static版，开箱即用，对于mac用户而言，也可以直接brew安装，命令行如下： 1brew install ffmpeg --with-faac --with-fdk-aac --with-ffplay --with-fontconfig --with-freetype --with-libass --with-libbluray --with-libcaca --with-libsoxr --with-libquvi --with-frei0r --with-libvidstab --with-libvorbis --with-libvpx --with-opencore-amr --with-openjpeg --with-openssl --with-opus --with-rtmpdump --with-schroedinger --with-speex --with-theroa --with-tools --with-x265 使用安装好之后就可以使用ffmpeg命令来压制你的视频文件了，下面为一个简单的命令行使用，对于压缩效果不满意的可以根据ffmpeg参数进行调整 1ffmpeg -i your_video -vcodec libx264 -preset fast -crf 20 -y -vf "scale=1920:-1" -acodec libmp3lame -ab 128k your_output 对该命令的常用参数介绍如下 命令行参数 意义 默认值 -i 输入文件 -vcodec 编码格式，支持h264和h265 xvid -preset 编码速率控制，编码加快，意味着信息丢失严重，输出视频质量差 -crt 控制输出质量的，范围0-51，0为无失真编码，建议18-28 23 -y 覆盖输出文件，即如果 output.wmv 文件已经存在的话，不经提示就覆盖掉 -vf 视频过滤器，样例中表示输出保持原始宽高比的1920视频 -acodec 音频编码方式 -ab 音频数据流量，一般选择32，64，96，128 推荐使用128 部分参数详细说明如下 —crt: 这个选项会直接影响到输出视频的码率，当设置了这个参数之后，再设置－b指定码率不会生效，本人对一个368M的avi文件进行压缩，结果如下(该视频总共450帧，时长15s) crf值 压缩后文件大小 20 8.14M 20 8.14M 30 2.40M —preset: 指定编码的配置,x264提供了一些预设值，而这些预设值可以通过preset指定。这些预设值有包括：ultrafast，superfast，veryfast，faster，fast，medium，slow，slower，veryslow和placebo。ultrafast编码速度最快，但压缩率低，生成的文件更大，placebo则正好相反。x264所取的默认值为medium。需要说明的是，preset主要是影响编码的速度，并不会很大的影响编码出来的结果的质量 常用参数可选视频参数ps:仅仅列出部分参数，部分高级选项请自行查阅官方文档 命令行参数 意义 默认值 -bitexact 使用标准比特率 -vb 指定视频的比特率，也就是码率 -s size 指定分辨率 -r rate 帧率 29.97 可选音频参数 命令行参数 意义 -ab 设置比特率(单位：bit/s，也许老版是kb/s)前面，-ac设为立体声时要以一半比特率来设置，比如192kbps的就设成96，转换 默认比特率都较小，要听到较高品质声音的话建议设到160kbps（80） -ar 设置音频采样率, 设置音频采样率 (单位：Hz)，PSP只认24000 -ac 设置声道数，1就是单声道，2就是立体声，转换单声道的TVrip可以用1（节省一半容量），高品质的DVDrip就可以用2 -an 取消音频 -vol 设置录制音量大小, 在转换时可以用这个提高音量 参考文献 ffmpeg官方文档]]></content>
      <categories>
        <category>技术杂谈</category>
      </categories>
      <tags>
        <tag>视频压缩</tag>
      </tags>
  </entry>
</search>
